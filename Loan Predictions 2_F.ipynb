{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Importing the necessary libraries required for analysis\n",
    "- Working directory is already set in the Jupyter Notebook\n",
    "- The problem statement is to create a binary classification in Python to predict the Loan Status (Loan_Status)\n",
    "of a particular individual. \n",
    "\n",
    "Methodology followed and quick inferences:\n",
    "    - All records with blank values will be imputed with mean (for continuous variables)\n",
    "    - We'll determine the nature of variables, continuous or categorical:\n",
    "        Categorical Features:\n",
    "            Gender\n",
    "            Married\n",
    "            Dependents\n",
    "            Education\n",
    "            Self_Employed\n",
    "            Loan_Amount_Term\n",
    "            Credit_History\n",
    "            Property_Area\n",
    "        Continuous Features:\n",
    "            ApplicantIncome\n",
    "            CoapplicantIncome\n",
    "            LoanAmount\n",
    "\n",
    "Upon quick look and EDA into the file we can see that the Loan_ID is an identifier field however, the\n",
    "Loan_Status field is a label field (dependant variable)\n",
    "\n",
    "We create plots to determine the outlier features for this dataset. \n",
    "\n",
    "For this current problem, we are going to use four algorithms\n",
    "\n",
    "- Logistic Regression\n",
    "- Support Vector Machine\n",
    "- Random Forest Classifer\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import cross_validation, metrics\n",
    "import sklearn.linear_model\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define modelfit function\n",
    "# ------------------------\n",
    "def modelfit(model, dtrain, dtest, predictors, performCV=True, printFeatImp=True, n_cvfolds=10):\n",
    "    # Fit the model to the data\n",
    "    model.fit(dtrain[predictors], dtrain['Loan_Status'])\n",
    "\n",
    "    # Predict training set:\n",
    "    dtrain_predictions = model.predict(dtrain[predictors])\n",
    "    dtrain_predprob = model.predict_proba(dtrain[predictors])[:, 1]\n",
    "\n",
    "    # Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_validation.cross_val_score(model, dtrain[predictors],\n",
    "                                                    dtrain['Loan_Status'], cv=n_cvfolds,\n",
    "                                                    scoring='roc_auc')\n",
    "\n",
    "    # Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Loan_Status'].values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Loan_Status'], dtrain_predprob))\n",
    "\n",
    "    if performCV:\n",
    "        print(\"CV Score : Mean %.7g | Std %.7g | Min %.7g | Max %.7g\" % (np.mean(cv_score),\n",
    "                                                                         np.std(cv_score),\n",
    "                                                                         np.min(cv_score),\n",
    "                                                                         np.max(cv_score)))\n",
    "\n",
    "    # Print Feature Importance:\n",
    "    if printFeatImp:\n",
    "        feat_imp = pd.Series(model.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "# -------------\n",
    "train = pd.read_csv('train_1.csv')\n",
    "print(type(train))\n",
    "#test = pd.read_csv('test_data.csv')\n",
    "\n",
    "\n",
    "# Basic data exploration and plots\n",
    "# --------------------------------\n",
    "print(train.head(5))\n",
    "train.describe()\n",
    "train['Education'].value_counts()\n",
    "\n",
    "cols = (['ApplicantIncome', 'LoanAmount',\n",
    "         'Loan_Amount_Term'])  # numeric features\n",
    "for c in cols:\n",
    "    train.hist(column=c, bins=50)\n",
    "    train.boxplot(column=c, by = 'Gender')\n",
    "\n",
    "pd.crosstab(train['Education'], train['Gender'], margins=True, normalize='columns')\n",
    "pd.crosstab(train['Credit_History'], train['Property_Area'], margins=True, normalize='columns')\n",
    "plt.scatter(train['LoanAmount'],train['Credit_History'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing data and imputation\n",
    "\n",
    "\"\"\"X = train.iloc[:,:-1].values\n",
    "#y = train.iloc[:, -1].values\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer.fit(train[:, 5:8])\n",
    "train[:, 5:8] = imputer.transform(train[:, 5:8])\n",
    "imputer_2 = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis =0)\n",
    "imputer_2.fit(train[:, 1:5])\n",
    "train[:, 1:5] = imputer_2.transform(train[:, 1:5])\n",
    "imputer_2.fit(train[:, 8:10])\n",
    "train[:, 8:10] = imputer_2.transform(train[:, 8:10])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "train[:, 0] = labelencoder_X(train[:,0])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1,2,3,4,8,9])\n",
    "\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "# ---------------------\n",
    "train_mod = train.copy()\n",
    "\n",
    "# Exclude observations with missing 'Credit_History'\n",
    "train_mod = train_mod.dropna(subset=['Credit_History']).reset_index()\n",
    "\n",
    "# Impute 'LoanAmount' with median values\n",
    "train_mod['LoanAmount'] = train_mod['LoanAmount'].fillna(train_mod['LoanAmount'].median())\n",
    "\n",
    "# For now, impute 'Gender' simply with 'Male' (the majority)\n",
    "train_mod['Gender'] = train_mod['Gender'].fillna('Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "# --------------\n",
    "number = LabelEncoder()\n",
    "\n",
    "train_mod['Gender'] = number.fit_transform(train_mod['Gender'].astype(str))\n",
    "\n",
    "train_mod['Education'] = number.fit_transform(train_mod['Education'].astype(str))\n",
    "\n",
    "train_mod['Loan_Status'] = number.fit_transform(train_mod['Loan_Status'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building: Logistic Regression\n",
    "# -----------------------------------\n",
    "# Create object of Logistic Regression\n",
    "model = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "# Select predictors\n",
    "# predictors = ['Credit_History', 'Education', 'Gender', 'ApplicantIncome', 'LoanAmount']\n",
    "predictors = ['Credit_History', 'Education', 'ApplicantIncome', 'LoanAmount']\n",
    "\n",
    "# Converting predictors and outcome to numpy array\n",
    "x_train = train_mod[predictors].values\n",
    "y_train = train_mod['Loan_Status'].values\n",
    "\n",
    "# Coss-validation\n",
    "# Simple K-Fold cross validation. 10 folds.\n",
    "cv = cross_validation.KFold(len(train_mod), n_folds=10)\n",
    "\n",
    "cv_score = cross_validation.cross_val_score(model, train_mod[predictors],\n",
    "                                            train_mod['Loan_Status'], cv=10,\n",
    "                                            scoring='roc_auc')\n",
    "results = []\n",
    "for traincv, testcv in cv:\n",
    "    model.fit(x_train[traincv, :], y_train[traincv])\n",
    "    x_test = train_mod.loc[testcv, predictors]\n",
    "    predicted = model.predict(x_test)\n",
    "    results.append(sum(abs(predicted - train_mod.ix[testcv, 'Loan_Status'].values))/len(testcv))\n",
    "\n",
    "print(\"\\nCV Results: \" + str(np.mean(100*np.array(results))) + \"% wrong predictions\")\n",
    "print(\"\\nCV Score: \" + str(np.mean(cv_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building: Decision Tree\n",
    "# -----------------------------\n",
    "# Create object of Decision Tree\n",
    "model = sklearn.tree.DecisionTreeClassifier()\n",
    "\n",
    "# Select predictors\n",
    "predictors = ['Credit_History', 'Education', 'Gender', 'ApplicantIncome', 'LoanAmount']\n",
    "\n",
    "# Converting predictors and outcome to numpy array\n",
    "x_train = train_mod[predictors].values\n",
    "y_train = train_mod['Loan_Status'].values\n",
    "\n",
    "# Fit model\n",
    "model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building: Random Forest\n",
    "# -----------------------------\n",
    "# Create object of Random Forest\n",
    "model = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "# Select all predictors\n",
    "predictors = ['Credit_History', 'Education', 'Gender', 'ApplicantIncome', 'LoanAmount']\n",
    "\n",
    "# Converting predictors and outcome to numpy array\n",
    "x_train = train_mod[predictors].values\n",
    "y_train = train_mod['Loan_Status'].values\n",
    "\n",
    "# Fit model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Feature importance\n",
    "featimp = pd.Series(model.feature_importances_, index=predictors).sort_values(ascending=False)\n",
    "print(featimp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier_SVC = SVC(kernel = 'linear', random_state = 42)\n",
    "classifier_SVC.fit(X_train, y_train)\n",
    "y_pred_SVC = classifier_SVC.predict(X_test)\n",
    "cm_SVC = confusion_matrix(y_test, y_pred_SVC)\n",
    "accuracy_score_SVC = accuracy_score(y_test, y_pred_SVC)\n",
    "print(\"Support Vector Machine accuracy score\", accuracy_score_SVC)\n",
    "print(\"Support Vector Machine confusion matrix\", cm_SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
